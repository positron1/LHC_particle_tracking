{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate score by known events\n"
     ]
    }
   ],
   "source": [
    "# Credit goes to Grzegorz Sionkowski for his awesome kernel\n",
    "# https://www.kaggle.com/sionek/mod-dbscan-x-100-parallel;\n",
    "# to Heng CherKeng for a python version and all improvements;\n",
    "# to Konstantin Lopuhin for pulishing the idea in\n",
    "# https://www.kaggle.com/c/trackml-particle-identification/discussion/57180\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "\n",
    "from sklearn.cluster.dbscan_ import dbscan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def find_labels(params):\n",
    "    hits, dz = params\n",
    "    a = hits['phi'].values\n",
    "    z = hits['z'].values\n",
    "    zr = hits['zr'].values\n",
    "    aa = a + np.sign(z) * dz * z\n",
    "\n",
    "    f0 = np.cos(aa)\n",
    "    f1 = np.sin(aa)\n",
    "    f2 = zr\n",
    "    X = StandardScaler().fit_transform(np.column_stack([f0, f1, f2]))\n",
    "\n",
    "    _, l = dbscan(X, eps=0.0045, min_samples=1, n_jobs=4)\n",
    "    return l + 1\n",
    "\n",
    "def add_count(l):\n",
    "    unique, reverse, count = np.unique(l, return_counts=True, return_inverse=True)\n",
    "    c = count[reverse]\n",
    "    c[np.where(l == 0)] = 0\n",
    "    c[np.where(c > 20)] = 0\n",
    "    return (l, c)\n",
    "\n",
    "def do_dbscan_predict(hits):\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    hits['r'] = np.sqrt(hits['x'] ** 2 + hits['y'] ** 2)\n",
    "    hits['zr'] = hits['z'] / hits['r']\n",
    "    hits['phi'] = np.arctan2(hits['y'], hits['x'])\n",
    "\n",
    "    params = []\n",
    "    for i in range(0, 20):\n",
    "        dz = i * 0.00001\n",
    "        params.append((hits, dz))\n",
    "        if i > 0:\n",
    "             params.append((hits, -dz))\n",
    "    # Kernel time is limited. So we skip some angles.\n",
    "    for i in range(20, 60):\n",
    "        dz = i * 0.00001\n",
    "        if i % 2 == 0:\n",
    "            params.append((hits, dz))\n",
    "        else:\n",
    "             params.append((hits, -dz))\n",
    "             \n",
    "    pool = Pool(processes=4)\n",
    "    labels_for_all_steps = pool.map(find_labels, params)\n",
    "    results = [add_count(l) for l in labels_for_all_steps]\n",
    "    pool.close()\n",
    "\n",
    "    labels, counts = results[0]\n",
    "    for i in range(1, len(results)):\n",
    "        l, c = results[i]\n",
    "        idx = np.where((c - counts > 0))[0]\n",
    "        labels[idx] = l[idx] + labels.max()\n",
    "        counts[idx] = c[idx]\n",
    "\n",
    "    print('time spent:', timeit.default_timer() - start_time)\n",
    "\n",
    "    return labels\n",
    "\n",
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission\n",
    "\n",
    "def run_dbscan():\n",
    "    data_dir = 'train_1'\n",
    "\n",
    "    event_ids = ['000001000']\n",
    "    sum = 0\n",
    "    sum_score = 0\n",
    "    for i, event_id in enumerate(event_ids):\n",
    "        hits, cells, particles, truth = load_event(data_dir + '/event' + event_id)\n",
    "        labels = do_dbscan_predict(hits)\n",
    "        submission = create_one_event_submission(0, hits['hit_id'].values, labels)\n",
    "        score = score_event(truth, submission)\n",
    "        print('[%2d] score : %0.8f' % (i, score))\n",
    "        sum_score += score\n",
    "        sum += 1\n",
    "\n",
    "    print('--------------------------------------')\n",
    "    print(sum_score / sum)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('estimate score by known events')\n",
    "    run_dbscan()\n",
    "\n",
    "    path_to_test = \"../input/test\"\n",
    "    test_dataset_submissions = []\n",
    "\n",
    "    create_submission = True  # True for submission\n",
    "    if create_submission:\n",
    "        print('process test events')\n",
    "        for event_id, hits in load_dataset(path_to_test, parts=['hits']):\n",
    "            print('Event ID: ', event_id)\n",
    "            labels = do_dbscan_predict(hits)\n",
    "            # Prepare submission for an event\n",
    "            one_submission = create_one_event_submission(event_id, hits['hit_id'].values, labels)\n",
    "            test_dataset_submissions.append(one_submission)\n",
    "\n",
    "        # Create submission file\n",
    "        submussion = pd.concat(test_dataset_submissions, axis=0)\n",
    "        submussion.to_csv('submission_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
